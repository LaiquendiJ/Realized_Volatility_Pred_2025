{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Factor Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import glob\n",
    "import os\n",
    "\n",
    "list_book_train = glob.glob(\n",
    "    'data/optiver-realized-volatility-prediction/book_train.parquet/*')\n",
    "list_trade_train = glob.glob(\n",
    "    'data/optiver-realized-volatility-prediction/trade_train.parquet/*')\n",
    "train_data = pl.read_csv(\n",
    "    'data/optiver-realized-volatility-prediction/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raise_if_nan(df: pl.DataFrame):\n",
    "    nan_counts = df.select([pl.col(col).is_nan().sum().alias(col) for col in df.columns])\n",
    "    total_nan = nan_counts.to_series().sum()\n",
    "    if total_nan > 0:\n",
    "        raise ValueError(\"DataFrame contains NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Feature Generation\n",
    "### 1.1.1 Book Features\n",
    "We first processes raw order book data and extracts meaningful features for modeling. The following table is the summary of the feature we generated from the original datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature Name            | Formula                                                                                                                                         | Reason for Inclusion                                                                                         |\n",
    "| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **`wap1/2`**              | $ \\frac{\\text{ask\\_price}_{1/2} \\cdot \\text{bid\\_size}_{1/2} + \\text{bid\\_price}_{1/2} \\cdot \\text{ask\\_size}_{1/2}}{\\text{ask\\_size}_{1/2} + \\text{bid\\_size}_{1/2}}$ | Weighted Average Price at depth 1/2. This smooths out the impact of individual order prices using size as weight. It approximates the \"fair\" market price better than simple mid-price. Including wap2 captures more of the limit order book’s shape. \n",
    "| **`bid_size_diff`**     | $\\text{bid\\_size}_1 - \\text{bid\\_size}_2$                                                                                      | Captures the change in demand depth between level 1 and level 2. Large differences may imply lower resilience in the order book.                  |\n",
    "| **`ask_size_diff`**     | $\\text{ask\\_size}_1-\\text{ask\\_size}_2$                                                                                | Measures ask-side change. Can signal a lack of liquidity on the sell side or increased selling pressure.                              |\n",
    "| **`price_spread`**      | $ \\frac{\\text{ask\\_price}_1}{\\text{bid\\_price}_1} - 1$                                                                                |A measure of transaction cost and short-term illiquidity.       |\n",
    "| **`order_imbalance_1/2`** | $\\frac{\\text{bid\\_size1/2} - \\text{ask\\_size1/2}}{\\text{bid\\_size1/2} + \\text{ask\\_size1/2}}$                                                     | Measures demand-supply pressure at level 1/2. Positive values imply buying pressure, negative values suggest selling pressure.              \n",
    "| **`depth_ratio`**       | $\\frac{\\text{bid\\_size}_1 + \\text{bid\\_size}_2}{\\text{ask\\_size}_1 + \\text{ask\\_size}_2}$                                             | Compares total buy-side depth to sell-side depth. Values > 1 suggest buy-side dominance.                                                   |\n",
    "| **`total_volume`**      | $ \\text{bid\\_size}_1 + \\text{bid\\_size}_2 + \\text{ask\\_size}_1 + \\text{ask\\_size}_2$                                                  | Captures overall liquidity in the limit order book. High volume typically corresponds to tighter spreads and lower volatility.             |\n",
    "| **`wap_diff`**          | $ \\text{wap1} - \\text{wap2}$                                                                                                              | Measures how much prices diverge between the top and next levels of the book. Large values may indicate price pressure or volatility. Useful for detecting price trends or pressure. |\n",
    "| **`log_return1/2`**       | $ \\log\\left( \\frac{\\text{wap1/2}_t}{\\text{wap1/2}_{t-1}} \\right)$                                                                        | Log return of using wap1/2. Used in volatility estimation and price dynamics modeling.                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_book_features = 'data/training_data/book_features'\n",
    "os.makedirs(output_dir_book_features, exist_ok=True)\n",
    "\n",
    "for file_path in list_book_train:\n",
    "    stock_id = int(file_path.split('=')[1])\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    # Step 1: Add price-level and liquidity-related features\n",
    "    df = df.with_columns([\n",
    "        # wap1/2\n",
    "        ((pl.col(\"ask_price1\") * pl.col(\"bid_size1\") + pl.col(\"bid_price1\") * pl.col(\"ask_size1\")) /\n",
    "            (pl.col(\"ask_size1\") + pl.col(\"bid_size1\"))\n",
    "         ).alias(\"wap1\"),\n",
    "        ((pl.col(\"ask_price2\") * pl.col(\"bid_size2\") + pl.col(\"bid_price2\") * pl.col(\"ask_size2\")) /\n",
    "            (pl.col(\"ask_size2\") + pl.col(\"bid_size2\"))\n",
    "         ).alias(\"wap2\"),\n",
    "        # bid_size_diff, ask_size_diff\n",
    "        (pl.col(\"bid_size1\") - pl.col(\"bid_size2\")-1).alias(\"bid_size_diff\"),\n",
    "        (pl.col(\"ask_size1\") / pl.col(\"ask_size2\")-1).alias(\"ask_size_diff\"),\n",
    "        # price_spread\n",
    "        (pl.col(\"ask_price1\") / pl.col(\"bid_price1\")-1).alias(\"price_spread\"),\n",
    "        # order_imbalance_1/2\n",
    "        ((pl.col(\"bid_size1\") - pl.col(\"ask_size1\")) /\n",
    "         (pl.col(\"bid_size1\") + pl.col(\"ask_size1\"))).alias(\"order_imbalance_1\"),\n",
    "        ((pl.col(\"bid_size2\") - pl.col(\"ask_size2\")) /\n",
    "         (pl.col(\"bid_size2\") + pl.col(\"ask_size2\"))).alias(\"order_imbalance_2\"),\n",
    "        # depth_ratio\n",
    "        ((pl.col(\"bid_size1\")+pl.col(\"bid_size2\")) /\n",
    "         (pl.col(\"ask_size1\") + pl.col(\"ask_size2\"))).alias(\"depth_ratio\"),\n",
    "        # total_volume\n",
    "        (pl.col(\"bid_size1\")+pl.col(\"bid_size2\")+pl.col(\"ask_size1\") +\n",
    "         pl.col(\"ask_size2\")).alias(\"total_volume\")\n",
    "    ])\n",
    "\n",
    "    # Step 2: Add dynamic (time-based) features\n",
    "    df = df.with_columns([\n",
    "        # wap_diff\n",
    "        (pl.col(\"wap1\")-pl.col(\"wap2\")).alias(\"wap_diff\"),\n",
    "        # log_return1/2\n",
    "        ((pl.col(\"wap1\") / pl.col(\"wap1\").shift(1)).log()).alias(\"log_return1\"),\n",
    "        ((pl.col(\"wap2\") / pl.col(\"wap2\").shift(1)).log()).alias(\"log_return2\")\n",
    "    ])\n",
    "\n",
    "    # Step 3: Drop raw order book columns to reduce storage and redundancy\n",
    "    df = df.drop([\n",
    "        \"ask_price1\", \"ask_price2\", \"ask_size1\", \"ask_size2\",\n",
    "        \"bid_price1\", \"bid_price2\", \"bid_size1\", \"bid_size2\"\n",
    "    ])\n",
    "\n",
    "    # Rows with null values for log_return1/2 are dropped. These nulls are a result of the `.diff()` operation within the calculation.\n",
    "    df = df.drop_nulls([\"log_return1\", \"log_return2\"])\n",
    "    raise_if_nan(df)\n",
    "\n",
    "    # Step 4: Save processed features per stock\n",
    "    file_name = f\"stock_id={stock_id}\"\n",
    "    file_path_o = os.path.join(output_dir_book_features, file_name)\n",
    "    df.write_parquet(file_path_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time_id</th><th>seconds_in_bucket</th><th>wap1</th><th>wap2</th><th>bid_size_diff</th><th>ask_size_diff</th><th>price_spread</th><th>order_imbalance_1</th><th>order_imbalance_2</th><th>depth_ratio</th><th>total_volume</th><th>wap_diff</th><th>log_return1</th><th>log_return2</th></tr><tr><td>i16</td><td>i16</td><td>f64</td><td>f64</td><td>i32</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>5</td><td>1</td><td>1.001327</td><td>1.000508</td><td>296</td><td>-0.636364</td><td>0.001599</td><td>0.974359</td><td>0.0</td><td>21.266667</td><td>334</td><td>0.000819</td><td>0.000005</td><td>0.0</td></tr><tr><td>5</td><td>3</td><td>1.001329</td><td>1.000508</td><td>316</td><td>-0.636364</td><td>0.001599</td><td>0.975904</td><td>0.0</td><td>22.6</td><td>354</td><td>0.000821</td><td>0.000001</td><td>0.0</td></tr><tr><td>5</td><td>4</td><td>1.001331</td><td>1.000508</td><td>366</td><td>-0.636364</td><td>0.001599</td><td>0.979058</td><td>0.0</td><td>25.933333</td><td>404</td><td>0.000823</td><td>0.000003</td><td>0.0</td></tr><tr><td>5</td><td>5</td><td>1.001321</td><td>1.000812</td><td>206</td><td>-0.636364</td><td>0.001572</td><td>0.965517</td><td>0.3125</td><td>16.6</td><td>264</td><td>0.000509</td><td>-0.00001</td><td>0.000304</td></tr><tr><td>5</td><td>6</td><td>1.001328</td><td>1.001023</td><td>267</td><td>-0.636364</td><td>0.001545</td><td>0.974359</td><td>0.568627</td><td>23.2</td><td>363</td><td>0.000306</td><td>0.000007</td><td>0.00021</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 14)\n",
       "┌─────────┬────────────┬──────────┬──────────┬───┬────────────┬──────────┬────────────┬────────────┐\n",
       "│ time_id ┆ seconds_in ┆ wap1     ┆ wap2     ┆ … ┆ total_volu ┆ wap_diff ┆ log_return ┆ log_return │\n",
       "│ ---     ┆ _bucket    ┆ ---      ┆ ---      ┆   ┆ me         ┆ ---      ┆ 1          ┆ 2          │\n",
       "│ i16     ┆ ---        ┆ f64      ┆ f64      ┆   ┆ ---        ┆ f64      ┆ ---        ┆ ---        │\n",
       "│         ┆ i16        ┆          ┆          ┆   ┆ i32        ┆          ┆ f64        ┆ f64        │\n",
       "╞═════════╪════════════╪══════════╪══════════╪═══╪════════════╪══════════╪════════════╪════════════╡\n",
       "│ 5       ┆ 1          ┆ 1.001327 ┆ 1.000508 ┆ … ┆ 334        ┆ 0.000819 ┆ 0.000005   ┆ 0.0        │\n",
       "│ 5       ┆ 3          ┆ 1.001329 ┆ 1.000508 ┆ … ┆ 354        ┆ 0.000821 ┆ 0.000001   ┆ 0.0        │\n",
       "│ 5       ┆ 4          ┆ 1.001331 ┆ 1.000508 ┆ … ┆ 404        ┆ 0.000823 ┆ 0.000003   ┆ 0.0        │\n",
       "│ 5       ┆ 5          ┆ 1.001321 ┆ 1.000812 ┆ … ┆ 264        ┆ 0.000509 ┆ -0.00001   ┆ 0.000304   │\n",
       "│ 5       ┆ 6          ┆ 1.001328 ┆ 1.001023 ┆ … ┆ 363        ┆ 0.000306 ┆ 0.000007   ┆ 0.00021    │\n",
       "└─────────┴────────────┴──────────┴──────────┴───┴────────────┴──────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('data/training_data/book_features/stock_id=5').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 10-Minute Time Window Book Features\n",
    "This code performs 10min-time-interval aggregation on order book data. It groups data by time_id within specified time intervals and computes key features such as realized volatility, logarithmic price range, and various mean values related to prices, order imbalances, and volume. The aggregated features are then saved as Parquet files named by stock ID, enabling efficient downstream analysis and modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_interval_book(df: pl.DataFrame, interval=None, interval_length=None) -> pl.DataFrame:\n",
    "    if interval:\n",
    "        start = interval * interval_length\n",
    "        end = (interval + 1) * interval_length\n",
    "\n",
    "        df_interval = df.filter((pl.col(\"seconds_in_bucket\") >= start) & (\n",
    "            pl.col(\"seconds_in_bucket\") < end))\n",
    "    else:\n",
    "        df_interval = df\n",
    "    df_agg = df_interval.group_by(\"time_id\").agg(\n",
    "\n",
    "        # realized_volatility\n",
    "        (pl.col(\"log_return1\").pow(2).sum()).sqrt().alias(\"realized_volatility1\"),\n",
    "        (pl.col(\"log_return2\").pow(2).sum()).sqrt().alias(\"realized_volatility2\"),\n",
    "        \n",
    "        # high_low_range\n",
    "        (pl.col(\"wap1\").max() / pl.col(\"wap1\").min()).log().alias(\"high_low_range\"),\n",
    "\n",
    "        # simple means\n",
    "        pl.col(\"wap1\").mean().alias(\"wap1_mean\"),\n",
    "        pl.col(\"wap2\").mean().alias(\"wap2_mean\"),\n",
    "        pl.col(\"wap_diff\").mean().alias(\"wap_diff_mean\"),\n",
    "        pl.col(\"order_imbalance_1\").mean().alias(\"order_imbalance_1_mean\"),\n",
    "        pl.col(\"order_imbalance_2\").mean().alias(\"order_imbalance_2_mean\"),\n",
    "        pl.col(\"depth_ratio\").mean().alias(\"depth_ratio_mean\"),\n",
    "        pl.col(\"total_volume\").mean().alias(\"total_volume_mean\"),\n",
    "        pl.col(\"price_spread\").mean().alias(\"price_spread_mean\"),\n",
    "\n",
    "        pl.col(\"bid_size_diff\").mean().alias(\"bid_size_diff_mean\"),\n",
    "        pl.col(\"ask_size_diff\").mean().alias(\"ask_size_diff_mean\"))\n",
    "\n",
    "    if interval != None:\n",
    "        df_agg = df_agg.rename({col: f\"{col}_{interval}\" if col !=\n",
    "                               \"time_id\" else \"time_id\" for col in df_agg.columns})\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_book_feature= glob.glob('data/training_data/book_features/*')\n",
    "output_dir_book_10min = 'data/training_data/book_features_10min'\n",
    "os.makedirs(output_dir_book_10min, exist_ok=True)\n",
    "\n",
    "for file_path in list_book_feature:\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    stock_id = int(file_path.split('=')[1])\n",
    "    stats = aggregate_interval_book(df)\n",
    "    raise_if_nan(stats)\n",
    "    file_name = f\"stock_id={stock_id}\"\n",
    "    file_path_o = os.path.join(output_dir_book_10min, file_name)\n",
    "\n",
    "    stats.write_parquet(file_path_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time_id</th><th>realized_volatility1</th><th>realized_volatility2</th><th>high_low_range</th><th>wap1_mean</th><th>wap2_mean</th><th>wap_diff_mean</th><th>order_imbalance_1_mean</th><th>order_imbalance_2_mean</th><th>depth_ratio_mean</th><th>total_volume_mean</th><th>price_spread_mean</th><th>bid_size_diff_mean</th><th>ask_size_diff_mean</th></tr><tr><td>i16</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>32646</td><td>0.007767</td><td>0.010397</td><td>0.002783</td><td>0.99851</td><td>0.998529</td><td>-0.000019</td><td>-0.07288</td><td>0.018719</td><td>4.618142</td><td>261.519553</td><td>0.0013</td><td>11.96648</td><td>8.515984</td></tr><tr><td>1057</td><td>0.003417</td><td>0.007791</td><td>0.004666</td><td>1.00184</td><td>1.00187</td><td>-0.00003</td><td>0.081909</td><td>0.170616</td><td>3.744964</td><td>275.017778</td><td>0.000674</td><td>0.933333</td><td>16.639692</td></tr><tr><td>6961</td><td>0.006789</td><td>0.009901</td><td>0.002613</td><td>0.999476</td><td>0.999361</td><td>0.000116</td><td>0.11866</td><td>0.022966</td><td>7.526675</td><td>257.713018</td><td>0.00109</td><td>32.446746</td><td>20.148408</td></tr><tr><td>14449</td><td>0.002718</td><td>0.003452</td><td>0.001743</td><td>0.999671</td><td>0.999832</td><td>-0.000161</td><td>0.328045</td><td>0.508676</td><td>16.257335</td><td>156.810185</td><td>0.000488</td><td>5.12037</td><td>11.067204</td></tr><tr><td>8938</td><td>0.006302</td><td>0.010583</td><td>0.007024</td><td>0.99933</td><td>0.99915</td><td>0.000181</td><td>0.216479</td><td>-0.078864</td><td>8.752918</td><td>216.449231</td><td>0.001351</td><td>41.96</td><td>6.384912</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 14)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ time_id ┆ realized_v ┆ realized_ ┆ high_low_ ┆ … ┆ total_vol ┆ price_spr ┆ bid_size_ ┆ ask_size_ │\n",
       "│ ---     ┆ olatility1 ┆ volatilit ┆ range     ┆   ┆ ume_mean  ┆ ead_mean  ┆ diff_mean ┆ diff_mean │\n",
       "│ i16     ┆ ---        ┆ y2        ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│         ┆ f64        ┆ ---       ┆ f64       ┆   ┆ f64       ┆ f32       ┆ f64       ┆ f64       │\n",
       "│         ┆            ┆ f64       ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 32646   ┆ 0.007767   ┆ 0.010397  ┆ 0.002783  ┆ … ┆ 261.51955 ┆ 0.0013    ┆ 11.96648  ┆ 8.515984  │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 3         ┆           ┆           ┆           │\n",
       "│ 1057    ┆ 0.003417   ┆ 0.007791  ┆ 0.004666  ┆ … ┆ 275.01777 ┆ 0.000674  ┆ 0.933333  ┆ 16.639692 │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 8         ┆           ┆           ┆           │\n",
       "│ 6961    ┆ 0.006789   ┆ 0.009901  ┆ 0.002613  ┆ … ┆ 257.71301 ┆ 0.00109   ┆ 32.446746 ┆ 20.148408 │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 8         ┆           ┆           ┆           │\n",
       "│ 14449   ┆ 0.002718   ┆ 0.003452  ┆ 0.001743  ┆ … ┆ 156.81018 ┆ 0.000488  ┆ 5.12037   ┆ 11.067204 │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 5         ┆           ┆           ┆           │\n",
       "│ 8938    ┆ 0.006302   ┆ 0.010583  ┆ 0.007024  ┆ … ┆ 216.44923 ┆ 0.001351  ┆ 41.96     ┆ 6.384912  │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 1         ┆           ┆           ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('data/training_data/book_features_10min/stock_id=5').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 150-Second Time Segment Book Features\n",
    "This code processes order book data by dividing each trading period into fixed-length intervals (in this case, 4 intervals of 150 seconds each). For each stock file, it aggregates features separately for each time interval using the aggregate_interval_book function, and then merges these interval-based feature sets into a single DataFrame keyed by time_id. The resulting combined features capture finer-grained temporal dynamics within the trading period. Finally, the aggregated data is saved as Parquet files organized by stock ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_book_features_10min = glob.glob(\n",
    "    'data/training_data/book_features_10min/*')\n",
    "output_dir_book_150sec = 'data/training_data/book_features_150sec'\n",
    "os.makedirs(output_dir_book_150sec, exist_ok=True)\n",
    "\n",
    "n_intervals = 4\n",
    "interval_length = 150\n",
    "for file_path in list_book_feature:\n",
    "    stock_id = int(file_path.split('=')[1].split('.')[0])\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    merged_df = None\n",
    "    for interval in range(n_intervals):\n",
    "        df_agg = aggregate_interval_book(df, interval, interval_length)\n",
    "        merged_df = df_agg if merged_df is None else merged_df.join(\n",
    "            df_agg, on=\"time_id\", how=\"left\")\n",
    "    raise_if_nan(merged_df)\n",
    "    file_name = f\"stock_id={stock_id}\"\n",
    "    file_path_o = os.path.join(output_dir_book_150sec, file_name)\n",
    "    merged_df.write_parquet(file_path_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 53)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time_id</th><th>realized_volatility1_0</th><th>realized_volatility2_0</th><th>high_low_range_0</th><th>wap1_mean_0</th><th>wap2_mean_0</th><th>wap_diff_mean_0</th><th>order_imbalance_1_mean_0</th><th>order_imbalance_2_mean_0</th><th>depth_ratio_mean_0</th><th>total_volume_mean_0</th><th>price_spread_mean_0</th><th>bid_size_diff_mean_0</th><th>ask_size_diff_mean_0</th><th>realized_volatility1_1</th><th>realized_volatility2_1</th><th>high_low_range_1</th><th>wap1_mean_1</th><th>wap2_mean_1</th><th>wap_diff_mean_1</th><th>order_imbalance_1_mean_1</th><th>order_imbalance_2_mean_1</th><th>depth_ratio_mean_1</th><th>total_volume_mean_1</th><th>price_spread_mean_1</th><th>bid_size_diff_mean_1</th><th>ask_size_diff_mean_1</th><th>realized_volatility1_2</th><th>realized_volatility2_2</th><th>high_low_range_2</th><th>wap1_mean_2</th><th>wap2_mean_2</th><th>wap_diff_mean_2</th><th>order_imbalance_1_mean_2</th><th>order_imbalance_2_mean_2</th><th>depth_ratio_mean_2</th><th>total_volume_mean_2</th><th>price_spread_mean_2</th><th>bid_size_diff_mean_2</th><th>ask_size_diff_mean_2</th><th>realized_volatility1_3</th><th>realized_volatility2_3</th><th>high_low_range_3</th><th>wap1_mean_3</th><th>wap2_mean_3</th><th>wap_diff_mean_3</th><th>order_imbalance_1_mean_3</th><th>order_imbalance_2_mean_3</th><th>depth_ratio_mean_3</th><th>total_volume_mean_3</th><th>price_spread_mean_3</th><th>bid_size_diff_mean_3</th><th>ask_size_diff_mean_3</th></tr><tr><td>i16</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>30547</td><td>0.006015</td><td>0.008576</td><td>0.00404</td><td>0.999129</td><td>0.999</td><td>0.000128</td><td>0.215959</td><td>0.121593</td><td>8.336699</td><td>296.849765</td><td>0.001229</td><td>-17.981221</td><td>10.679583</td><td>0.004141</td><td>0.004387</td><td>0.002749</td><td>0.999521</td><td>0.999645</td><td>-0.000124</td><td>-0.149258</td><td>0.060261</td><td>1.373644</td><td>391.237288</td><td>0.001213</td><td>-67.508475</td><td>6.871591</td><td>0.00311</td><td>0.002826</td><td>0.002848</td><td>0.999084</td><td>0.999033</td><td>0.000051</td><td>0.117405</td><td>0.25692</td><td>9.407518</td><td>204.137255</td><td>0.001213</td><td>-19.235294</td><td>1.377748</td><td>0.00264</td><td>0.005645</td><td>0.001527</td><td>0.99819</td><td>0.997606</td><td>0.000584</td><td>0.569069</td><td>-0.122372</td><td>9.852087</td><td>273.727273</td><td>0.001335</td><td>30.681818</td><td>1.17684</td></tr><tr><td>5392</td><td>0.004102</td><td>0.005832</td><td>0.004712</td><td>0.996065</td><td>0.996041</td><td>0.000024</td><td>-0.333597</td><td>-0.33047</td><td>1.668498</td><td>242.944853</td><td>0.000585</td><td>-37.220588</td><td>5.630982</td><td>0.001576</td><td>0.003042</td><td>0.001538</td><td>0.99515</td><td>0.995156</td><td>-0.000006</td><td>-0.460082</td><td>-0.371156</td><td>1.698817</td><td>207.507042</td><td>0.00063</td><td>-28.732394</td><td>7.330091</td><td>0.002074</td><td>0.003149</td><td>0.001633</td><td>0.995306</td><td>0.995424</td><td>-0.000118</td><td>-0.261058</td><td>0.116803</td><td>3.118714</td><td>283.716418</td><td>0.000635</td><td>-61.41791</td><td>9.35995</td><td>0.001011</td><td>0.001545</td><td>0.001509</td><td>0.995001</td><td>0.994866</td><td>0.000135</td><td>-0.396953</td><td>-0.597733</td><td>0.938764</td><td>237.282609</td><td>0.000463</td><td>-11.478261</td><td>-0.180047</td></tr><tr><td>9343</td><td>0.006852</td><td>0.008016</td><td>0.005926</td><td>0.996283</td><td>0.996348</td><td>-0.000065</td><td>-0.086474</td><td>0.123769</td><td>12.706524</td><td>161.668394</td><td>0.000671</td><td>-26.541451</td><td>5.714986</td><td>0.002872</td><td>0.004387</td><td>0.005588</td><td>0.996119</td><td>0.996047</td><td>0.000072</td><td>-0.117447</td><td>-0.202635</td><td>2.183346</td><td>132.661017</td><td>0.000656</td><td>-14.220339</td><td>3.370797</td><td>0.001797</td><td>0.00278</td><td>0.001795</td><td>0.994126</td><td>0.994148</td><td>-0.000023</td><td>-0.588484</td><td>-0.367322</td><td>2.905517</td><td>157.494624</td><td>0.000732</td><td>-18.419355</td><td>4.95948</td><td>0.002422</td><td>0.003006</td><td>0.002415</td><td>0.995686</td><td>0.995829</td><td>-0.000143</td><td>0.127995</td><td>0.462921</td><td>24.365892</td><td>149.030769</td><td>0.000681</td><td>-14.261538</td><td>5.995368</td></tr><tr><td>13276</td><td>0.003559</td><td>0.004024</td><td>0.001621</td><td>0.999992</td><td>0.999828</td><td>0.000164</td><td>-0.305966</td><td>-0.571466</td><td>0.632861</td><td>277.314815</td><td>0.000677</td><td>34.808642</td><td>16.296238</td><td>0.000959</td><td>0.001546</td><td>0.000653</td><td>1.000159</td><td>0.999992</td><td>0.000167</td><td>-0.458335</td><td>-0.731747</td><td>0.307994</td><td>245.409091</td><td>0.0006</td><td>45.568182</td><td>21.856908</td><td>0.001043</td><td>0.001212</td><td>0.001219</td><td>0.99965</td><td>0.999605</td><td>0.000045</td><td>-0.495523</td><td>-0.587422</td><td>0.70244</td><td>204.023256</td><td>0.000455</td><td>21.348837</td><td>8.035399</td><td>0.001072</td><td>0.001007</td><td>0.001201</td><td>0.999747</td><td>0.999244</td><td>0.000503</td><td>0.097511</td><td>-0.654429</td><td>1.055237</td><td>168.111111</td><td>0.001051</td><td>63.444444</td><td>5.457412</td></tr><tr><td>18483</td><td>0.009602</td><td>0.009498</td><td>0.004285</td><td>1.003473</td><td>1.003471</td><td>0.000002</td><td>0.078312</td><td>-0.00153</td><td>2.079671</td><td>254.763636</td><td>0.001309</td><td>26.486364</td><td>9.833753</td><td>0.002614</td><td>0.003352</td><td>0.00156</td><td>1.002805</td><td>1.002739</td><td>0.000066</td><td>0.14277</td><td>0.038894</td><td>1.507675</td><td>363.73913</td><td>0.001424</td><td>46.0</td><td>3.18549</td><td>0.003051</td><td>0.00511</td><td>0.002508</td><td>1.002967</td><td>1.00288</td><td>0.000087</td><td>0.14606</td><td>0.032599</td><td>1.269478</td><td>217.241935</td><td>0.001423</td><td>30.016129</td><td>5.916149</td><td>0.003932</td><td>0.003798</td><td>0.002703</td><td>1.004749</td><td>1.004891</td><td>-0.000142</td><td>0.012923</td><td>0.151611</td><td>3.877646</td><td>202.971429</td><td>0.001203</td><td>8.671429</td><td>22.712517</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 53)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ time_id ┆ realized_v ┆ realized_ ┆ high_low_ ┆ … ┆ total_vol ┆ price_spr ┆ bid_size_ ┆ ask_size_ │\n",
       "│ ---     ┆ olatility1 ┆ volatilit ┆ range_0   ┆   ┆ ume_mean_ ┆ ead_mean_ ┆ diff_mean ┆ diff_mean │\n",
       "│ i16     ┆ _0         ┆ y2_0      ┆ ---       ┆   ┆ 3         ┆ 3         ┆ _3        ┆ _3        │\n",
       "│         ┆ ---        ┆ ---       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│         ┆ f64        ┆ f64       ┆           ┆   ┆ f64       ┆ f32       ┆ f64       ┆ f64       │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 30547   ┆ 0.006015   ┆ 0.008576  ┆ 0.00404   ┆ … ┆ 273.72727 ┆ 0.001335  ┆ 30.681818 ┆ 1.17684   │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 3         ┆           ┆           ┆           │\n",
       "│ 5392    ┆ 0.004102   ┆ 0.005832  ┆ 0.004712  ┆ … ┆ 237.28260 ┆ 0.000463  ┆ -11.47826 ┆ -0.180047 │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 9         ┆           ┆ 1         ┆           │\n",
       "│ 9343    ┆ 0.006852   ┆ 0.008016  ┆ 0.005926  ┆ … ┆ 149.03076 ┆ 0.000681  ┆ -14.26153 ┆ 5.995368  │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 9         ┆           ┆ 8         ┆           │\n",
       "│ 13276   ┆ 0.003559   ┆ 0.004024  ┆ 0.001621  ┆ … ┆ 168.11111 ┆ 0.001051  ┆ 63.444444 ┆ 5.457412  │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 1         ┆           ┆           ┆           │\n",
       "│ 18483   ┆ 0.009602   ┆ 0.009498  ┆ 0.004285  ┆ … ┆ 202.97142 ┆ 0.001203  ┆ 8.671429  ┆ 22.712517 │\n",
       "│         ┆            ┆           ┆           ┆   ┆ 9         ┆           ┆           ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('data/training_data/book_features_150sec/stock_id=5').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Trade Features \n",
    "This code processes trade data for stocks, computing additional features such as average trade size per order and the logarithmic return of trade prices. The logarithmic return is calculated as the log of the ratio between the current price and the previous price. Rows with null values resulting from this calculation (due to missing previous prices) are removed to ensure data quality. The cleaned and enriched DataFrame is then saved as Parquet files, organized by stock ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_trade_features = 'data/training_data/trade_features'\n",
    "os.makedirs(output_dir_trade_features, exist_ok=True)\n",
    "\n",
    "for file_path in list_trade_train:\n",
    "    stock_id = int(file_path.split('=')[1])\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    df = df.with_columns([\n",
    "        # size_per_order\n",
    "        (pl.col(\"size\")/pl.col(\"order_count\")).alias(\"size_per_order\"),\n",
    "        # trade_log_return\n",
    "         ((pl.col(\"price\") / pl.col(\"price\").shift(1)).log()).alias(\"trade_log_return\")\n",
    "    ])\n",
    "\n",
    "    # Rows with null values for trade_log_return are dropped. These nulls are a result of the `.diff()` operation within the calculation.\n",
    "    df = df.drop_nulls([\"trade_log_return\"])\n",
    "    raise_if_nan(df)\n",
    "    file_name = f\"stock_id={stock_id}\"\n",
    "    file_path_o = os.path.join(output_dir_trade_features, file_name)\n",
    "    df.write_parquet(file_path_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time_id</th><th>seconds_in_bucket</th><th>price</th><th>size</th><th>order_count</th><th>size_per_order</th><th>trade_log_return</th></tr><tr><td>i16</td><td>i16</td><td>f32</td><td>i32</td><td>i16</td><td>f64</td><td>f32</td></tr></thead><tbody><tr><td>5</td><td>14</td><td>1.001395</td><td>6</td><td>4</td><td>1.5</td><td>0.000304</td></tr><tr><td>5</td><td>15</td><td>1.001639</td><td>2</td><td>2</td><td>1.0</td><td>0.000244</td></tr><tr><td>5</td><td>25</td><td>1.001375</td><td>1</td><td>1</td><td>1.0</td><td>-0.000264</td></tr><tr><td>5</td><td>31</td><td>1.00128</td><td>2</td><td>1</td><td>2.0</td><td>-0.000095</td></tr><tr><td>5</td><td>38</td><td>1.001009</td><td>4</td><td>1</td><td>4.0</td><td>-0.000271</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬───────────────────┬──────────┬──────┬─────────────┬────────────────┬──────────────────┐\n",
       "│ time_id ┆ seconds_in_bucket ┆ price    ┆ size ┆ order_count ┆ size_per_order ┆ trade_log_return │\n",
       "│ ---     ┆ ---               ┆ ---      ┆ ---  ┆ ---         ┆ ---            ┆ ---              │\n",
       "│ i16     ┆ i16               ┆ f32      ┆ i32  ┆ i16         ┆ f64            ┆ f32              │\n",
       "╞═════════╪═══════════════════╪══════════╪══════╪═════════════╪════════════════╪══════════════════╡\n",
       "│ 5       ┆ 14                ┆ 1.001395 ┆ 6    ┆ 4           ┆ 1.5            ┆ 0.000304         │\n",
       "│ 5       ┆ 15                ┆ 1.001639 ┆ 2    ┆ 2           ┆ 1.0            ┆ 0.000244         │\n",
       "│ 5       ┆ 25                ┆ 1.001375 ┆ 1    ┆ 1           ┆ 1.0            ┆ -0.000264        │\n",
       "│ 5       ┆ 31                ┆ 1.00128  ┆ 2    ┆ 1           ┆ 2.0            ┆ -0.000095        │\n",
       "│ 5       ┆ 38                ┆ 1.001009 ┆ 4    ┆ 1           ┆ 4.0            ┆ -0.000271        │\n",
       "└─────────┴───────────────────┴──────────┴──────┴─────────────┴────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('data/training_data/trade_features/stock_id=5').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 10-Minute Time Window Trade Features\n",
    "This code aggregates trade data into 10-minute intervals by grouping on time_id. For each interval, it calculates various statistical features, including realized volatility from squared log returns, price range, mean price, mean order size, total traded size, and standard deviation of trade sizes. The processed features are saved to separate Parquet files for each stock, enabling efficient downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_trade_feature = glob.glob('data/training_data/trade_features/*')\n",
    "output_dir_trade_10min = 'data/training_data/trade_features_10min'\n",
    "os.makedirs(output_dir_trade_10min, exist_ok=True)\n",
    "\n",
    "for file_path in list_trade_feature:\n",
    "    df = pl.read_parquet(file_path)\n",
    "\n",
    "    stock_id = int(file_path.split('=')[1])\n",
    "\n",
    "    stats = df.group_by(\"time_id\").agg(\n",
    "\n",
    "        # trade_realized_volatility\n",
    "        (pl.col(\"trade_log_return\").pow(2).sum()).sqrt().alias(\n",
    "            \"trade_realized_volatility\"),\n",
    "\n",
    "        # trade_price_range\n",
    "        (pl.col(\"price\").max() / pl.col(\"price\").min()\n",
    "         ).log().alias(\"trade_price_range\"),\n",
    "\n",
    "        # means\n",
    "        pl.col(\"price\").mean().alias(\"trade_price_mean\"),\n",
    "        pl.col(\"size_per_order\").mean().alias(\"size_per_order_mean\"),\n",
    "        pl.col(\"order_count\").mean().alias(\"order_count_mean\"),\n",
    "\n",
    "        # sums\n",
    "        pl.col(\"size\").sum().alias(\"total_size\"),\n",
    "        pl.col(\"order_count\").sum().alias(\"total_order\"),\n",
    "\n",
    "        # std\n",
    "        pl.col(\"size\").std().alias(\"size_std\"))\n",
    "    stats = stats.drop_nulls([\"size_std\"])\n",
    "    raise_if_nan(stats)\n",
    "    file_name = f\"stock_id={stock_id}\"\n",
    "    file_path_o = os.path.join(output_dir_trade_10min, file_name)\n",
    "\n",
    "    stats.write_parquet(file_path_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_830, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time_id</th><th>trade_realized_volatility</th><th>trade_price_range</th><th>trade_price_mean</th><th>size_per_order_mean</th><th>order_count_mean</th><th>total_size</th><th>total_order</th><th>size_std</th></tr><tr><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>i32</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>31616</td><td>0.005685</td><td>0.006168</td><td>0.999802</td><td>20.183201</td><td>3.62963</td><td>2667</td><td>98</td><td>135.384732</td></tr><tr><td>19034</td><td>0.001793</td><td>0.003602</td><td>1.000157</td><td>9.846065</td><td>2.75</td><td>1121</td><td>66</td><td>81.35776</td></tr><tr><td>5648</td><td>0.00262</td><td>0.00382</td><td>1.001939</td><td>7.303922</td><td>2.294118</td><td>491</td><td>39</td><td>46.120606</td></tr><tr><td>12728</td><td>0.00577</td><td>0.001369</td><td>1.000697</td><td>18.029984</td><td>3.157895</td><td>1091</td><td>60</td><td>85.751784</td></tr><tr><td>8664</td><td>0.004336</td><td>0.003202</td><td>1.000435</td><td>8.2861</td><td>2.5</td><td>1204</td><td>65</td><td>145.031519</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>23836</td><td>0.003161</td><td>0.001728</td><td>0.999713</td><td>32.433729</td><td>3.076923</td><td>2432</td><td>80</td><td>151.024033</td></tr><tr><td>1688</td><td>0.005305</td><td>0.006925</td><td>0.99995</td><td>12.74</td><td>2.566667</td><td>1482</td><td>77</td><td>68.649334</td></tr><tr><td>5728</td><td>0.00785</td><td>0.017071</td><td>0.994098</td><td>21.780793</td><td>7.705882</td><td>6251</td><td>262</td><td>248.185309</td></tr><tr><td>4037</td><td>0.004132</td><td>0.00689</td><td>1.002741</td><td>19.911834</td><td>4.97619</td><td>6432</td><td>209</td><td>434.57608</td></tr><tr><td>25551</td><td>0.00348</td><td>0.005281</td><td>0.999619</td><td>5.954113</td><td>3.121951</td><td>1094</td><td>128</td><td>81.407444</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_830, 9)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ time_id ┆ trade_real ┆ trade_pri ┆ trade_pri ┆ … ┆ order_cou ┆ total_siz ┆ total_ord ┆ size_std  │\n",
       "│ ---     ┆ ized_volat ┆ ce_range  ┆ ce_mean   ┆   ┆ nt_mean   ┆ e         ┆ er        ┆ ---       │\n",
       "│ i16     ┆ ility      ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ f64       │\n",
       "│         ┆ ---        ┆ f32       ┆ f32       ┆   ┆ f64       ┆ i32       ┆ i64       ┆           │\n",
       "│         ┆ f32        ┆           ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 31616   ┆ 0.005685   ┆ 0.006168  ┆ 0.999802  ┆ … ┆ 3.62963   ┆ 2667      ┆ 98        ┆ 135.38473 │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 2         │\n",
       "│ 19034   ┆ 0.001793   ┆ 0.003602  ┆ 1.000157  ┆ … ┆ 2.75      ┆ 1121      ┆ 66        ┆ 81.35776  │\n",
       "│ 5648    ┆ 0.00262    ┆ 0.00382   ┆ 1.001939  ┆ … ┆ 2.294118  ┆ 491       ┆ 39        ┆ 46.120606 │\n",
       "│ 12728   ┆ 0.00577    ┆ 0.001369  ┆ 1.000697  ┆ … ┆ 3.157895  ┆ 1091      ┆ 60        ┆ 85.751784 │\n",
       "│ 8664    ┆ 0.004336   ┆ 0.003202  ┆ 1.000435  ┆ … ┆ 2.5       ┆ 1204      ┆ 65        ┆ 145.03151 │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9         │\n",
       "│ …       ┆ …          ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 23836   ┆ 0.003161   ┆ 0.001728  ┆ 0.999713  ┆ … ┆ 3.076923  ┆ 2432      ┆ 80        ┆ 151.02403 │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3         │\n",
       "│ 1688    ┆ 0.005305   ┆ 0.006925  ┆ 0.99995   ┆ … ┆ 2.566667  ┆ 1482      ┆ 77        ┆ 68.649334 │\n",
       "│ 5728    ┆ 0.00785    ┆ 0.017071  ┆ 0.994098  ┆ … ┆ 7.705882  ┆ 6251      ┆ 262       ┆ 248.18530 │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9         │\n",
       "│ 4037    ┆ 0.004132   ┆ 0.00689   ┆ 1.002741  ┆ … ┆ 4.97619   ┆ 6432      ┆ 209       ┆ 434.57608 │\n",
       "│ 25551   ┆ 0.00348    ┆ 0.005281  ┆ 0.999619  ┆ … ┆ 3.121951  ┆ 1094      ┆ 128       ┆ 81.407444 │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('data/training_data/trade_features_10min/stock_id=5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
